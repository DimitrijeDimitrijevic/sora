//go:build integration

package proxy

import (
	"context"
	"testing"
	"time"

	"github.com/migadu/sora/cluster"
	"github.com/migadu/sora/config"
	"github.com/migadu/sora/server"
)

// TestAffinityFailoverIntegration tests the complete affinity failover flow
func TestAffinityFailoverIntegration(t *testing.T) {
	t.Run("HealthyBackendAffinity", testHealthyBackendAffinity)
	t.Run("UnhealthyBackendFailover", testUnhealthyBackendFailover)
	t.Run("FailoverUpdatesPropagation", testFailoverUpdatesPropagation)
	t.Run("BackendAutoRecovery", testBackendAutoRecovery)
}

// testHealthyBackendAffinity verifies affinity routing to healthy backend
func testHealthyBackendAffinity(t *testing.T) {
	// Create cluster and affinity manager
	cluster1, err := createTestCluster("node-1", 22946, []string{})
	if err != nil {
		t.Fatalf("Failed to create cluster: %v", err)
	}
	defer cluster1.Shutdown()

	affinity := server.NewAffinityManager(cluster1, true, 24*time.Hour, 1*time.Hour)

	// Create connection manager with test backends
	backends := []string{"backend1:143", "backend2:143", "backend3:143"}
	connMgr, err := NewConnectionManager(backends, 143, false, false, false, 5*time.Second)
	if err != nil {
		t.Fatalf("Failed to create connection manager: %v", err)
	}
	connMgr.SetAffinityManager(affinity)

	// Set affinity for user
	affinity.SetBackend("user@example.com", "backend2:143", "imap")

	// All backends should be healthy initially
	for _, backend := range backends {
		if !connMgr.IsBackendHealthy(backend) {
			t.Errorf("Backend %s should be healthy initially", backend)
		}
	}

	// Determine route with affinity
	result, err := DetermineRoute(RouteParams{
		Ctx:                context.Background(),
		Username:           "user@example.com",
		Protocol:           "imap",
		IsPrelookupAccount: false,
		RoutingInfo:        nil,
		ConnManager:        connMgr,
		EnableAffinity:     true,
		ProxyName:          "Test Proxy",
	})

	if err != nil {
		t.Fatalf("DetermineRoute failed: %v", err)
	}

	// Should route to affinity backend
	if result.PreferredAddr != "backend2:143" {
		t.Errorf("Expected route to 'backend2:143', got '%s'", result.PreferredAddr)
	}
	if result.RoutingMethod != "affinity" {
		t.Errorf("Expected routing method 'affinity', got '%s'", result.RoutingMethod)
	}

	t.Logf("✅ PASS: User routed to affinity backend (healthy)")
}

// testUnhealthyBackendFailover verifies failover when affinity backend is unhealthy
func testUnhealthyBackendFailover(t *testing.T) {
	// Create cluster and affinity manager
	cluster1, err := createTestCluster("node-1", 23946, []string{})
	if err != nil {
		t.Fatalf("Failed to create cluster: %v", err)
	}
	defer cluster1.Shutdown()

	affinity := server.NewAffinityManager(cluster1, true, 24*time.Hour, 1*time.Hour)

	// Create connection manager
	backends := []string{"backend1:143", "backend2:143", "backend3:143"}
	connMgr, err := NewConnectionManager(backends, 143, false, false, false, 5*time.Second)
	if err != nil {
		t.Fatalf("Failed to create connection manager: %v", err)
	}
	connMgr.SetAffinityManager(affinity)

	// Set affinity for user to backend2
	affinity.SetBackend("user@example.com", "backend2:143", "imap")

	// Verify affinity is set
	backend, found := affinity.GetBackend("user@example.com", "imap")
	if !found || backend != "backend2:143" {
		t.Fatalf("Affinity not set correctly")
	}

	// Simulate backend2 becoming unhealthy (3 consecutive failures)
	for i := 0; i < 3; i++ {
		connMgr.RecordConnectionFailure("backend2:143")
	}

	// Verify backend2 is now unhealthy
	if connMgr.IsBackendHealthy("backend2:143") {
		t.Error("Backend2 should be unhealthy after 3 failures")
	}

	// Determine route - should detect unhealthy backend and delete affinity
	result, err := DetermineRoute(RouteParams{
		Ctx:                context.Background(),
		Username:           "user@example.com",
		Protocol:           "imap",
		IsPrelookupAccount: false,
		RoutingInfo:        nil,
		ConnManager:        connMgr,
		EnableAffinity:     true,
		ProxyName:          "Test Proxy",
	})

	if err != nil {
		t.Fatalf("DetermineRoute failed: %v", err)
	}

	// Should NOT route to backend2 (unhealthy)
	if result.PreferredAddr == "backend2:143" {
		t.Error("Should not route to unhealthy backend2")
	}

	// Should fall back to round-robin (no preferred address)
	if result.PreferredAddr != "" {
		t.Logf("Note: PreferredAddr is '%s', expected empty for round-robin", result.PreferredAddr)
	}

	// Verify affinity was deleted
	time.Sleep(100 * time.Millisecond)
	_, found = affinity.GetBackend("user@example.com", "imap")
	if found {
		t.Error("Affinity should be deleted after detecting unhealthy backend")
	}

	t.Logf("✅ PASS: Unhealthy backend detected, affinity deleted, fell back to round-robin")
}

// testFailoverUpdatesPropagation verifies affinity updates propagate during failover
func testFailoverUpdatesPropagation(t *testing.T) {
	// Create two-node cluster
	cluster1, err := createTestCluster("node-1", 24946, []string{})
	if err != nil {
		t.Fatalf("Failed to create cluster 1: %v", err)
	}
	defer cluster1.Shutdown()

	cluster2, err := createTestCluster("node-2", 24947, []string{"127.0.0.1:24946"})
	if err != nil {
		t.Fatalf("Failed to create cluster 2: %v", err)
	}
	defer cluster2.Shutdown()

	// Wait for cluster formation
	time.Sleep(500 * time.Millisecond)

	// Create affinity managers on both nodes
	affinity1 := server.NewAffinityManager(cluster1, true, 24*time.Hour, 1*time.Hour)
	affinity2 := server.NewAffinityManager(cluster2, true, 24*time.Hour, 1*time.Hour)

	// Set initial affinity on node1
	affinity1.SetBackend("user@example.com", "backend1:143", "imap")

	// Wait for propagation to node2
	time.Sleep(200 * time.Millisecond)

	// Verify both nodes have same affinity
	backend1, found1 := affinity1.GetBackend("user@example.com", "imap")
	backend2, found2 := affinity2.GetBackend("user@example.com", "imap")
	if !found1 || !found2 || backend1 != "backend1:143" || backend2 != "backend1:143" {
		t.Fatalf("Initial affinity not synchronized: node1=%s, node2=%s", backend1, backend2)
	}

	// Simulate failover on node1: Update affinity to backend2
	affinity1.UpdateBackend("user@example.com", "backend1:143", "backend2:143", "imap")

	// Wait for failover update to propagate to node2
	time.Sleep(300 * time.Millisecond)

	// Verify both nodes now have new affinity
	backend1, found1 = affinity1.GetBackend("user@example.com", "imap")
	backend2, found2 = affinity2.GetBackend("user@example.com", "imap")

	if !found1 || !found2 {
		t.Fatal("Affinity should exist on both nodes after failover")
	}

	if backend1 != "backend2:143" || backend2 != "backend2:143" {
		t.Errorf("Failover not propagated correctly: node1=%s, node2=%s", backend1, backend2)
	}

	t.Logf("✅ PASS: Failover update propagated from node1 to node2 (backend1→backend2)")
}

// testBackendAutoRecovery verifies backends auto-recover after 1 minute
func testBackendAutoRecovery(t *testing.T) {
	// Create connection manager
	backends := []string{"backend1:143"}
	connMgr, err := NewConnectionManager(backends, 143, false, false, false, 5*time.Second)
	if err != nil {
		t.Fatalf("Failed to create connection manager: %v", err)
	}

	// Backend should be healthy initially
	if !connMgr.IsBackendHealthy("backend1:143") {
		t.Fatal("Backend should be healthy initially")
	}

	// Record 3 consecutive failures to mark unhealthy
	for i := 0; i < 3; i++ {
		wasJustMarkedUnhealthy := connMgr.RecordConnectionFailure("backend1:143")
		if i == 2 && !wasJustMarkedUnhealthy {
			t.Error("Backend should be marked unhealthy after 3rd failure")
		}
	}

	// Verify backend is unhealthy
	if connMgr.IsBackendHealthy("backend1:143") {
		t.Fatal("Backend should be unhealthy after 3 failures")
	}

	// NOTE: Auto-recovery happens after 1 minute, which is too long for a test.
	// We'll test the immediate state and document the auto-recovery behavior.

	t.Logf("Backend marked unhealthy after 3 consecutive failures")
	t.Logf("Note: Auto-recovery occurs after 1 minute (too long for integration test)")

	// To test immediate recovery, record a success
	connMgr.RecordConnectionSuccess("backend1:143")

	// Should be healthy again immediately
	if !connMgr.IsBackendHealthy("backend1:143") {
		t.Error("Backend should be healthy immediately after successful connection")
	}

	t.Logf("✅ PASS: Backend recovery works (immediate on success, auto after 1 min)")
}

// TestAffinityCleanup verifies expired affinities are cleaned up
func TestAffinityCleanup(t *testing.T) {
	// Create cluster
	cluster1, err := createTestCluster("node-1", 25946, []string{})
	if err != nil {
		t.Fatalf("Failed to create cluster: %v", err)
	}
	defer cluster1.Shutdown()

	// Create affinity manager with SHORT TTL for testing (5 seconds)
	affinity := server.NewAffinityManager(cluster1, true, 5*time.Second, 1*time.Second)

	// Set affinity
	affinity.SetBackend("user@example.com", "backend1:143", "imap")

	// Verify affinity exists
	backend, found := affinity.GetBackend("user@example.com", "imap")
	if !found || backend != "backend1:143" {
		t.Fatal("Affinity should be set")
	}

	// Wait for TTL to expire + cleanup interval
	t.Logf("Waiting 7 seconds for affinity to expire and cleanup to run...")
	time.Sleep(7 * time.Second)

	// Verify affinity is cleaned up
	_, found = affinity.GetBackend("user@example.com", "imap")
	if found {
		t.Error("Expired affinity should be cleaned up")
	}

	t.Logf("✅ PASS: Expired affinities are automatically cleaned up")
}

// Helper function to create test cluster
func createTestCluster(nodeID string, port int, peers []string) (*cluster.Manager, error) {
	cfg := config.ClusterConfig{
		Enabled:   true,
		BindAddr:  "127.0.0.1",
		BindPort:  port,
		NodeID:    nodeID,
		Peers:     peers,
		SecretKey: "MTIzNDU2Nzg5MDEyMzQ1Njc4OTAxMjM0NTY3ODkwMTI=", // Base64-encoded 32-byte key
	}

	return cluster.New(cfg)
}
